{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from lavis.models import load_model_and_preprocess"
   ],
   "id": "b6586761770daa55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:12:18.038822Z",
     "start_time": "2024-09-28T15:12:18.036345Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.__version__)\n",
   "id": "9112552e14e5168a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Carga del Modelo",
   "id": "57d58ca2051a0fd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:12:20.863416Z",
     "start_time": "2024-09-28T15:12:20.860523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device available: \", device)"
   ],
   "id": "676de0b846137bb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available:  cuda\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:25:33.536364Z",
     "start_time": "2024-09-28T15:16:52.354898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(str(device))\n",
    "model, vis_processors, _ = load_model_and_preprocess(\n",
    "    name=\"blip2_t5\", model_type=\"pretrain_flant5xxl\", is_eval=True, device=str(device)\n",
    ")"
   ],
   "id": "f2e4374ad25b0c88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:01<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b912bd633a574235ac1ad840f6affa3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\TFG_Jorge\\venv\\Lib\\site-packages\\lavis\\models\\blip2_models\\blip2.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(cached_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Carga de las preguntas",
   "id": "9610a28b71608ce2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:27:32.426062Z",
     "start_time": "2024-09-27T22:27:32.426062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from orchestartors_delete.QuestionDataOrchestrator import QuestionDataOrchestrator\n",
    "from data_controler.MongoDB_data_controler.MongoDBControler import MongoDBController\n",
    "\n",
    "mongodb_controller = MongoDBController()\n",
    "mongodb_connection = mongodb_controller.build_connection(host='localhost', port=27017)\n",
    "mongodb_loader = mongodb_controller.build_loader(mongodb_connection, db_name='categorization_data')\n",
    "\n",
    "orchestrator = QuestionDataOrchestrator(mongodb_loader)\n",
    "text_file_paths = [\"data/modeling/questions_txt/Represented_activities_categorization.txt\",\n",
    "                       \"data/modeling/questions_txt/Subjet_categorization.txt\", \n",
    "                        \"data/modeling/questions_txt/Context_categorization.txt\",]\n",
    "\n",
    "for file_path in text_file_paths:\n",
    "    orchestrator.update_questions_from_text(file_path)"
   ],
   "id": "b73c9b328a52aa3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "subject = QuestionDataOrchestrator(mongodb_loader).load_data(\"Subjet\").initialize_data()",
   "id": "25fcf7b802af2848",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "activity = QuestionDataOrchestrator(mongodb_loader).load_data(\"Activitie\").initialize_data()",
   "id": "c65eddd1d0b5fffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "context = QuestionDataOrchestrator(mongodb_loader).load_data(\"Context\").initialize_data()",
   "id": "23560c1d33e19a4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Conexion con la base de datos de imagenes",
   "id": "d252b03809c47e97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "repo_name = \"Yorchz/mi-dataset-de-images\""
   ],
   "id": "24a9a941c64c8ced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Carga del dataset",
   "id": "3da0a37d3a323529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data_controler.HuggingFace_data_controler.HuggingFaceController import HuggingFaceController\n",
    "\n",
    "huggingface_controller = HuggingFaceController()\n",
    "huggingface_connection = huggingface_controller.build_connection(token)\n",
    "dataset = huggingface_controller.build_loader(repo_name).load_images()"
   ],
   "id": "bff934e4b91243db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creamos el csv para guardar los datos",
   "id": "4e97a4c126d8f7b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "headers = ['Imagen', 'Numero_personas', 'Relevancia', 'Sexo', 'Localidad', 'Edad', 'Tipo_grupo', 'Tipo_actividad', 'Actividad']\n",
    "\n",
    "df = pd.DataFrame(columns=headers)\n",
    "df.to_csv('pruebas/data1.csv', index=False)"
   ],
   "id": "e012942e0fa6bd98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_rows(data):\n",
    "    new_rows = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    df = pd.read_csv('pruebas/data1.csv')\n",
    "    df = pd.concat([df, new_rows], ignore_index=True)\n",
    "    df.to_csv('pruebas/data1.csv', index=False)"
   ],
   "id": "6628d2950bbe9cc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Realizamos pregutas y subida de las respuestas ",
   "id": "128d200488e73f7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompts = [f\"Question: {getattr(subject, f'question{i}')}? Answer:\" for i in range(1, 7)] + \\\n",
    "          [f\"Question: {getattr(activity, f'question{i}')}? Answer:\" for i in range(1, 3)]\n",
    "images = [item['image'] for item in dataset['train']]\n",
    "labels = [item['label'] for item in dataset['train']]"
   ],
   "id": "7e55812685ed506c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def model_generate(image_tensor, prompt, model):\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    return model.generate({\"image\": image_tensor, \"prompt\": prompt})"
   ],
   "id": "b10852a0ebd12f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ajusta según las dimensiones esperadas por el modelo\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ajusta según los requisitos del modelo\n",
    "])\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image = images[i]\n",
    "    label = labels[i]\n",
    "    \n",
    "    # Transformar la imagen a tensor\n",
    "    image_tensor = transform(image)\n",
    "    print(f\"Image nº{i+1} processed\")\n",
    "    \n",
    "    # Generar respuestas para cada prompt\n",
    "    row = [label]\n",
    "    for prompt in prompts:\n",
    "        answer = model_generate(image_tensor, prompt, model)\n",
    "        row.append(answer)\n",
    "    \n",
    "    # Añadir la fila al CSV\n",
    "    add_rows([row])"
   ],
   "id": "bdcc4f76970dc653",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5a446f7a7b02a76e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Intentos individuales para afinar las preguntas una a una ",
   "id": "777c571fa678fd4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ajusta según las dimensiones esperadas por el modelo\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Ajusta según los requisitos del modelo\n",
    "])"
   ],
   "id": "54512a2e11a3f0e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(subject.question1)",
   "id": "7975d54347a10a58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(model_generate(transform(images[9]), subject.question1, model))",
   "id": "c1a6fdea573b25b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(images[15])",
   "id": "1e859f5681e56d7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "459cf63c46a1d170",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
